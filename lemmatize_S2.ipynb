{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319e2032",
   "metadata": {},
   "source": [
    "# Lemmatize Semantic Scholar papers using Spark NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ccc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "import sparknlp\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ee1f5",
   "metadata": {},
   "source": [
    "## 1. Read papers and concatenate the `title` and `paperAbstract` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f6fcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/22 01:10:18 WARN metastore.ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n",
      "[Stage 16:===============================================>(19881 + 119) / 20000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers before language filtering: 204457855\n",
      "CPU times: user 62.5 ms, sys: 5.27 ms, total: 67.8 ms\n",
      "Wall time: 19.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Loading papers table text fields, and concatenating them for lemmatization\n",
    "S2papers = spark.sql(\"SELECT id, title, paperAbstract FROM parquet.`/export/ml4ds/IntelComp/Datalake/SemanticScholar/20220201/papers.parquet`\")\n",
    "S2papers = S2papers.repartition(numPartitions=20000)\n",
    "##For development purposes only\n",
    "#S2papers = S2papers.sample(fraction=0.0001)\n",
    "\n",
    "#Concatenate text fields to lemmatize\n",
    "S2papers = (\n",
    "    S2papers.withColumn(\"rawtext\",F.concat_ws('. ', \"title\", \"paperAbstract\"))\n",
    "    .drop(\"title\")\n",
    "    .drop(\"paperAbstract\")\n",
    ")\n",
    "\n",
    "print('Number of papers before language filtering:', S2papers.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba78d8",
   "metadata": {},
   "source": [
    "## 2. Filter abstracts that are not in English Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba2ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld_wiki_tatoeba_cnn_21 download started this may take some time.\n",
      "Approximate size to download 7.1 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in English: 150077538\n",
      "CPU times: user 1.37 s, sys: 236 ms, total: 1.61 s\n",
      "Wall time: 2h 12min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Pipeline for language detection\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"rawtext\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "languageDetector = LanguageDetectorDL.pretrained() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"language\")\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    "    .setStages([\n",
    "      documentAssembler,\n",
    "      languageDetector\n",
    "    ])\n",
    "\n",
    "#Apply language detection pipeline\n",
    "S2papers = pipeline.fit(S2papers).transform(S2papers)\n",
    "S2papers = (\n",
    "    S2papers.filter(F.col(\"language.result\")[0]==\"en\")\n",
    "    .drop(\"language\")\n",
    ")\n",
    "\n",
    "print('Number of papers in English:', S2papers.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d59da",
   "metadata": {},
   "source": [
    "## 3. Define and Run Lemmatization Pipeline\n",
    "\n",
    "   - We work on documents created in Subsection 2\n",
    "   - Sentence Detection and Tokenizer applied to detect tokens\n",
    "   - Lemmatization is carried out\n",
    "   - Stopwords are applied\n",
    "   - Punctuation symbols are removed\n",
    "   - Result is converted back from Spark NLP annotations to string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecf0f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "CPU times: user 94.8 ms, sys: 7.38 ms, total: 102 ms\n",
      "Wall time: 4.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Next, we carry out the lemmatization pipeline\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "stopWords = StopWordsCleaner() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setOutputCol(\"cleanlemma\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"cleanlemma\"]) \\\n",
    "    .setOutputCol(\"normalizedlemma\") \\\n",
    "    .setLowercase(True) \\\n",
    "    .setCleanupPatterns([\"\"\"[^\\w\\d\\s]\"\"\"])\n",
    "\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['normalizedlemma'])\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    "    .setStages([\n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      lemmatizer,\n",
    "      stopWords,\n",
    "      normalizer,\n",
    "      finisher\n",
    "])\n",
    "\n",
    "#We apply pipeline and recover lemmas as string\n",
    "S2papers = pipeline.fit(S2papers).transform(S2papers)\n",
    "\n",
    "udf_back2str = F.udf(lambda x:' '.join(list(x)), StringType() )\n",
    "S2papers = (\n",
    "    S2papers.withColumn(\"lemmas\",udf_back2str(F.col(\"finished_normalizedlemma\")))\n",
    "    .drop(\"rawtext\")\n",
    "    .drop(\"finished_normalizedlemma\")\n",
    ")\n",
    "\n",
    "#Show results of validation for n papers\n",
    "#S2papers.show(n=10, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63e174",
   "metadata": {},
   "source": [
    "## 4. Save a table with `id` and `lemmas` to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c5b911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.33 s, sys: 403 ms, total: 2.73 s\n",
      "Wall time: 3h 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Save calculated lemmas to HDFS\n",
    "dir_parquet = Path(\"/export/ml4ds/IntelComp/Datalake/SemanticScholar/20220201\")\n",
    "\n",
    "S2papers.coalesce(1000).write.parquet(\n",
    "    dir_parquet.joinpath(f\"papers_NLP.parquet\").as_posix(),\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9416b",
   "metadata": {},
   "source": [
    "## 5. Optional: Check that the generated table looks OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf2a8e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/22 09:20:40 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "22/03/22 09:20:40 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "22/03/22 09:20:40 WARN metastore.ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lemmatized papers: 150077538\n",
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | 64706fbc01a509210366aedac123fe534159e3b7                                                                                 \n",
      " lemmas | exhibition gustave courbet                                                                                               \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | b16390c663cf43db0e9301cb81ddb00e894447d5                                                                                 \n",
      " lemmas | role k channel alveolar bronchial epithelial repair process                                                              \n",
      "-RECORD 2--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | 1ce5def24ba497a27c8742cb8b0ad5a6602cfb1c                                                                                 \n",
      " lemmas | unsupervised framework extract normalize product attribute multiple web site develop unsupervised framework simultane... \n",
      "-RECORD 3--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | 2e9b0773b244b41785bd9bab575fdb8f3ec87f90                                                                                 \n",
      " lemmas | activating paraaminobenzoic acid sowing properties seed winter grain crops forage cereals                                \n",
      "-RECORD 4--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | 66e0dc1ba08c185918f7a8c6c43d411ca5300de3                                                                                 \n",
      " lemmas | note disambiguation language development toward proper meaningform association                                           \n",
      "-RECORD 5--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | 3afea11172d45d07d7c5319a1f6a00344862a93d                                                                                 \n",
      " lemmas | evolution tornadic storms abstract life cycle classification severe local storm propose add fourth stage quasisteady ... \n",
      "-RECORD 6--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | 6ea05ee7fa5b1d6cd566070f2d856e3d3177c8bd                                                                                 \n",
      " lemmas | improving students ability learning english grammar communicative task                                                   \n",
      "-RECORD 7--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | f5622c31b86a90263bb7aa7870a98074d96a71b0                                                                                 \n",
      " lemmas | microcomputerbased vehicle rout schedule software abstract study report commercially available microcomputer software... \n",
      "-RECORD 8--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | 181f8ec536136a2f00a6543aaea978d59fa36073                                                                                 \n",
      " lemmas | vitamin d level rickets index among infant nurse mother tripoli libya study conduct assess status vitamin d rickets i... \n",
      "-RECORD 9--------------------------------------------------------------------------------------------------------------------------\n",
      " id     | 4040a84b7a9be4d7c46f0c01085ba29e45844778                                                                                 \n",
      " lemmas | pediatric osteomyelitis septic arthritis pathology neonatal disease abstract morphologic histologic examination fifty... \n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 9.08 ms, sys: 595 Âµs, total: 9.67 ms\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Test that the saved table is correct\n",
    "S2papers = spark.sql(\"SELECT * FROM parquet.`/export/ml4ds/IntelComp/Datalake/SemanticScholar/20220201/papers_NLP.parquet`\")\n",
    "print('Number of lemmatized papers:', S2papers.count())\n",
    "S2papers.show(n=10, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c4e59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/22 09:39:43 WARN metastore.ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n",
      "22/03/22 09:39:43 WARN metastore.ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in joint table: 150077680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 000007d87901458ae6f88092ab0ac01388b11fcf                                                                                 \n",
      " fieldsOfStudy | []                                                                                                                       \n",
      " lemmas        | philippines people country call vernacular architecture call folk architecture mostly identify rural bahay kubo liter... \n",
      "-RECORD 1---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 00001c5efb21112a47918810af4281e3922803b8                                                                                 \n",
      " fieldsOfStudy | []                                                                                                                       \n",
      " lemmas        | reason become teacher influence future secondary mathematics teacher teach competence intention toward teach career s... \n",
      "-RECORD 2---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 0000263f4f82fbe5bebf29563876c7272d3a9b88                                                                                 \n",
      " fieldsOfStudy | [History]                                                                                                                \n",
      " lemmas        | cobbetts weekly political register london saturday october 9 1819 sir robert peel baronet cottonweaver 146               \n",
      "-RECORD 3---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 0000281f67982d92f0a9bd2802112aa48427c660                                                                                 \n",
      " fieldsOfStudy | [Psychology]                                                                                                             \n",
      " lemmas        | acceptance caregiving married divorced custodial mothers fathers abstract study examine whether difference gender fam... \n",
      "-RECORD 4---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 00002b100707f83729dc1f0377c999b7bfe3e6d3                                                                                 \n",
      " fieldsOfStudy | []                                                                                                                       \n",
      " lemmas        | answer reviewer 2 v                                                                                                      \n",
      "-RECORD 5---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 0000386529040d744200aad8fba1170f79209fd3                                                                                 \n",
      " fieldsOfStudy | [History]                                                                                                                \n",
      " lemmas        | old english suprasegmentals                                                                                              \n",
      "-RECORD 6---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 00003f6077eb0dd01f1e0499a4ac10b50195d640                                                                                 \n",
      " fieldsOfStudy | [Medicine]                                                                                                               \n",
      " lemmas        | cumulative risk physiological stress responses african american adolescents objective investigate association compone... \n",
      "-RECORD 7---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 00004ddfe8089303589fb12cddc05fefc7a0bd96                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | using static total causal ordering protocols achieve ordered view synchrony view synchronous communication vsc servic... \n",
      "-RECORD 8---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 000051c2d8eff18654e5eaf3e636c02028ef96bb                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | author think paper highly cite                                                                                           \n",
      "-RECORD 9---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 0000681ed9f71e8210d443a1b2229af104386818                                                                                 \n",
      " fieldsOfStudy | []                                                                                                                       \n",
      " lemmas        | table contents                                                                                                           \n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 241 ms, sys: 30.6 ms, total: 272 ms\n",
      "Wall time: 2min 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "papers = spark.sql(\"SELECT id, fieldsOfStudy FROM parquet.`/export/ml4ds/IntelComp/Datalake/SemanticScholar/20220201/papers.parquet`\")\n",
    "lemmas = spark.sql(\"SELECT id, lemmas FROM parquet.`/export/ml4ds/IntelComp/Datalake/SemanticScholar/20220201/papers_NLP.parquet`\")\n",
    "\n",
    "papers_lemmas = (papers.join(lemmas, papers.id ==  lemmas.id, \"right\")\n",
    "                      .drop(lemmas.id)\n",
    "                )\n",
    "\n",
    "print('Number of papers in joint table:', papers_lemmas.count())\n",
    "papers_lemmas.show(n=10, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9322a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in Computer Science: 13654631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 00004ddfe8089303589fb12cddc05fefc7a0bd96                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | using static total causal ordering protocols achieve ordered view synchrony view synchronous communication vsc servic... \n",
      "-RECORD 1---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 000051c2d8eff18654e5eaf3e636c02028ef96bb                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | author think paper highly cite                                                                                           \n",
      "-RECORD 2---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 00042289b5ddd6284a06dedf5272e4d27a2a5f6c                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | adaptive pulse shape cpofdm synchronization paper present new algorithm blind time offset estimation cyclic prefixort... \n",
      "-RECORD 3---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 000469a0fedfa15d33f8e0ab9f2d6f3309d7d45a                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | research integration capppdm based step xml deal product data exchange share capppdm integration network environmenti... \n",
      "-RECORD 4---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 000517d8f2b37864718111f832c6fb1cf1d1f79b                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | security vulnerability analysis correspond mitigation passwordbased authentication use offline personal authenticatio... \n",
      "-RECORD 5---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 0005db3f7cbffb7ce4d4dac237d273caa0eb4021                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | improving particle swarm optimization convergence controllable parameter particle swarm optimization algorithm value ... \n",
      "-RECORD 6---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 0006750da7d720e03fadd98dd20e014f9efab039                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | xquery interpreter                                                                                                       \n",
      "-RECORD 7---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 00070f1ddef29e150ceb6b2d8686541ba7ac0c4d                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | testbed network performance evaluation ipv4 ipv6 network layer protocol paper represent testbed perform measure evalu... \n",
      "-RECORD 8---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 0007a869cd502070f049d8779ee6bbfb06277283                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | improved density peaks clustering based sharedneighbors local cores manifold data sets novel cluster algorithm fast s... \n",
      "-RECORD 9---------------------------------------------------------------------------------------------------------------------------------\n",
      " id            | 00080ed6324e584726730b53a4d592d5aa7cbcf5                                                                                 \n",
      " fieldsOfStudy | [Computer Science]                                                                                                       \n",
      " lemmas        | microelectromechanical configuration optically reconfigurable gate array paper present proposal novel optically recon... \n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 201 ms, sys: 34.5 ms, total: 235 ms\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Using SQL Expression\n",
    "papers_lemmas = papers_lemmas.filter(F.array_contains(\"fieldsOfStudy\", 'Computer Science'))\n",
    "print('Number of papers in Computer Science:', papers_lemmas.count())\n",
    "papers_lemmas.show(n=10, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667f4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
